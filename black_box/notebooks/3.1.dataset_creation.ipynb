{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Copyright 2025 Claudio Giovannoni, Carlo Metta, Anna Monreale,\n",
    "# Salvatore Rinzivillo, Andrea Berti, Sara Colantonio, and\n",
    "# Francesca Pratesi\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nfL-3eL9WfoZ"
   },
   "source": "# Dataset Creation and Labeling Process"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive/ABELE_prostate/claudio/'\n",
    "sys.path.append(os.path.join(BASE_DIR, 'code'))\n",
    "\n",
    "from crop_data_utils import file_checker\n",
    "from dataset_creation_utils import dataset_creation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "csv_dir = os.path.join(BASE_DIR, 'black_box', 'data', 'CSV', 'dataframes', 'val')\n",
    "traindf_path = os.path.join(csv_dir, 'traindf.csv')\n",
    "valdf_path = os.path.join(csv_dir, 'valdf.csv')\n",
    "testdf_path = os.path.join(csv_dir, 'testdf.csv')\n",
    "\n",
    "output_dir = os.path.join(BASE_DIR, 'black_box', 'data', 'dataset')\n",
    "destination_path_train = os.path.join(output_dir, 'val', 'train')\n",
    "destination_path_valid = os.path.join(output_dir, 'val', 'valid')\n",
    "destination_path_test = os.path.join(output_dir, 'val', 'test')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# load train and test mapping csv\n",
    "traindf = pd.read_csv(traindf_path)\n",
    "valdf = pd.read_csv(valdf_path)\n",
    "testdf = pd.read_csv(testdf_path)\n",
    "\n",
    "print(len(traindf)+len(valdf)+len(testdf))\n",
    "print(traindf.shape)\n",
    "print(valdf.shape)\n",
    "print(testdf.shape)\n",
    "# checking class distribution in the dfs\n",
    "dataframes = [traindf, testdf, valdf]\n",
    "for i, df in enumerate(dataframes):\n",
    "    label_counts = df['label'].value_counts().sort_index()\n",
    "    total_samples = len(df)\n",
    "    percentage_per_class = (label_counts / total_samples) * 100\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'Count': label_counts,\n",
    "        'Percentage': percentage_per_class\n",
    "    }).sort_index()\n",
    "\n",
    "    print(f\"\\nClass balance for dataframe {i + 1}:\\n\")\n",
    "    print(result_df)\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HAIwDw7snRYw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700127329560,
     "user_tz": -60,
     "elapsed": 1751,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "3478cd4e-1dac-41e9-e49b-d02f85031d11"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "21222\n",
      "(16971, 4)\n",
      "(2125, 4)\n",
      "(2126, 4)\n",
      "\n",
      "Class balance for dataframe 1:\n",
      "\n",
      "   Count  Percentage\n",
      "0  12257   72.223204\n",
      "1   4714   27.776796\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for dataframe 2:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1519    71.44873\n",
      "1    607    28.55127\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for dataframe 3:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1512   71.152941\n",
      "1    613   28.847059\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## create different dataset for each modality"
   ],
   "metadata": {
    "id": "9zPcxpFuTQCA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df_path_adc = os.path.join(output_dir, 'adc')\n",
    "\n",
    "destination_path_train_adc = os.path.join(df_path_adc, 'train')\n",
    "destination_path_valid_adc = os.path.join(df_path_adc, 'valid')\n",
    "destination_path_test_adc = os.path.join(df_path_adc, 'test')\n",
    "\n",
    "traindf_adc_path = os.path.join(df_path_adc,'traindf_adc.csv')\n",
    "valdf_adc_path = os.path.join(df_path_adc,'valdf_adc.csv')\n",
    "testdf_adc_path = os.path.join(df_path_adc,'testdf_adc.csv')\n",
    "\n",
    "\n",
    "df_path_t2w = os.path.join(output_dir, 't2w')\n",
    "\n",
    "destination_path_train_t2w = os.path.join(df_path_t2w, 'train')\n",
    "destination_path_valid_t2w = os.path.join(df_path_t2w, 'valid')\n",
    "destination_path_test_t2w = os.path.join(df_path_t2w, 'test')\n",
    "\n",
    "traindf_t2w_path = os.path.join(df_path_t2w,'traindf_t2w.csv')\n",
    "valdf_t2w_path = os.path.join(df_path_t2w,'valdf_t2w.csv')\n",
    "testdf_t2w_path = os.path.join(df_path_t2w,'testdf_t2w.csv')\n",
    "\n",
    "\n",
    "df_path_hbv = os.path.join(output_dir, 'hbv')\n",
    "\n",
    "destination_path_train_hbv = os.path.join(df_path_hbv, 'train')\n",
    "destination_path_valid_hbv = os.path.join(df_path_hbv, 'valid')\n",
    "destination_path_test_hbv = os.path.join(df_path_hbv, 'test')\n",
    "\n",
    "traindf_hbv_path = os.path.join(df_path_hbv,'traindf_hbv.csv')\n",
    "valdf_hbv_path = os.path.join(df_path_hbv,'valdf_hbv.csv')\n",
    "testdf_hbv_path = os.path.join(df_path_hbv,'testdf_hbv.csv')"
   ],
   "metadata": {
    "id": "P3RCvXCMPoao"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# checking class distribution in the dfs\n",
    "traindf_adc=pd.read_csv(traindf_adc_path)\n",
    "valdf_adc=pd.read_csv(valdf_adc_path)\n",
    "testdf_adc=pd.read_csv(testdf_adc_path)\n",
    "\n",
    "traindf_t2w=pd.read_csv(traindf_t2w_path)\n",
    "valdf_t2w=pd.read_csv(valdf_t2w_path)\n",
    "testdf_t2w=pd.read_csv(testdf_t2w_path)\n",
    "\n",
    "traindf_hbv=pd.read_csv(traindf_hbv_path)\n",
    "valdf_hbv=pd.read_csv(valdf_hbv_path)\n",
    "testdf_hbv=pd.read_csv(testdf_hbv_path)\n",
    "\n",
    "traindf_adc.name = 'traindf_adc'\n",
    "valdf_adc.name = 'valdf_adc'\n",
    "testdf_adc.name = 'testdf_adc'\n",
    "\n",
    "traindf_t2w.name = 'traindf_t2w'\n",
    "valdf_t2w.name = 'valdf_t2w'\n",
    "testdf_t2w.name = 'testdf_t2w'\n",
    "\n",
    "traindf_hbv.name = 'traindf_hbv'\n",
    "valdf_hbv.name = 'valdf_hbv'\n",
    "testdf_hbv.name = 'testdf_hbv'\n",
    "\n",
    "print(traindf_adc.name,traindf_adc.shape)\n",
    "print(valdf_adc.name,valdf_adc.shape)\n",
    "print(testdf_adc.name,testdf_adc.shape)\n",
    "\n",
    "print(traindf_t2w.name,traindf_t2w.shape)\n",
    "print(valdf_t2w.name,valdf_t2w.shape)\n",
    "print(testdf_t2w.name,testdf_t2w.shape)\n",
    "\n",
    "print(traindf_hbv.name,traindf_hbv.shape)\n",
    "print(valdf_hbv.name,valdf_hbv.shape)\n",
    "print(testdf_hbv.name,testdf_hbv.shape)\n",
    "\n",
    "dataframes = [traindf_adc, testdf_adc, valdf_adc,\n",
    "              traindf_t2w, testdf_t2w, valdf_t2w,\n",
    "              traindf_hbv, testdf_hbv, valdf_hbv]\n",
    "\n",
    "for df in dataframes:\n",
    "    label_counts = df['label'].value_counts().sort_index()\n",
    "    total_samples = len(df)\n",
    "\n",
    "    percentage_per_class = (label_counts / total_samples) * 100\n",
    "\n",
    "    print(f\"\\nClass balance for {df.name}:\\n\")\n",
    "    print(result_df)\n",
    "    print(\"\\n\" + \"=\" * 40 + \"\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKacqrMgQgvR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694593240349,
     "user_tz": -120,
     "elapsed": 3957,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "a2fc41cf-5fbb-47b6-e5ad-744774ae1ee0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "traindf_adc (5201, 4)\n",
      "valdf_adc (1121, 4)\n",
      "testdf_adc (1109, 4)\n",
      "traindf_t2w (5201, 4)\n",
      "valdf_t2w (1121, 4)\n",
      "testdf_t2w (1109, 4)\n",
      "\n",
      "Class balance for traindf_adc:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for testdf_adc:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for valdf_adc:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for traindf_t2w:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for testdf_t2w:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n",
      "\n",
      "Class balance for valdf_t2w:\n",
      "\n",
      "   Count  Percentage\n",
      "0   1594   71.097235\n",
      "1    648   28.902765\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9o3FEU8qfVA"
   },
   "source": [
    "# Binary Dataset Creation (Stacked)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENQqt026QW6F"
   },
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4106607,
     "status": "ok",
     "timestamp": 1700131452222,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     },
     "user_tz": -60
    },
    "id": "K001pXM8K66e",
    "outputId": "f16f60f8-774f-424e-9103-e807776e8a34"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 50 images out of 16971.\n",
      "Processed 100 images out of 16971.\n",
      "Processed 150 images out of 16971.\n",
      "Processed 200 images out of 16971.\n",
      "Processed 250 images out of 16971.\n",
      "Processed 300 images out of 16971.\n",
      "Processed 350 images out of 16971.\n",
      "Processed 400 images out of 16971.\n",
      "Processed 450 images out of 16971.\n",
      "Processed 500 images out of 16971.\n",
      "Processed 550 images out of 16971.\n",
      "Processed 600 images out of 16971.\n",
      "Processed 650 images out of 16971.\n",
      "Processed 700 images out of 16971.\n",
      "Processed 750 images out of 16971.\n",
      "Processed 800 images out of 16971.\n",
      "Processed 850 images out of 16971.\n",
      "Processed 900 images out of 16971.\n",
      "Processed 950 images out of 16971.\n",
      "Processed 1000 images out of 16971.\n",
      "Processed 1050 images out of 16971.\n",
      "Processed 1100 images out of 16971.\n",
      "Processed 1150 images out of 16971.\n",
      "Processed 1200 images out of 16971.\n",
      "Processed 1250 images out of 16971.\n",
      "Processed 1300 images out of 16971.\n",
      "Processed 1350 images out of 16971.\n",
      "Processed 1400 images out of 16971.\n",
      "Processed 1450 images out of 16971.\n",
      "Processed 1500 images out of 16971.\n",
      "Processed 1550 images out of 16971.\n",
      "Processed 1600 images out of 16971.\n",
      "Processed 1650 images out of 16971.\n",
      "Processed 1700 images out of 16971.\n",
      "Processed 1750 images out of 16971.\n",
      "Processed 1800 images out of 16971.\n",
      "Processed 1850 images out of 16971.\n",
      "Processed 1900 images out of 16971.\n",
      "Processed 1950 images out of 16971.\n",
      "Processed 2000 images out of 16971.\n",
      "Processed 2050 images out of 16971.\n",
      "Processed 2100 images out of 16971.\n",
      "Processed 2150 images out of 16971.\n",
      "Processed 2200 images out of 16971.\n",
      "Processed 2250 images out of 16971.\n",
      "Processed 2300 images out of 16971.\n",
      "Processed 2350 images out of 16971.\n",
      "Processed 2400 images out of 16971.\n",
      "Processed 2450 images out of 16971.\n",
      "Processed 2500 images out of 16971.\n",
      "Processed 2550 images out of 16971.\n",
      "Processed 2600 images out of 16971.\n",
      "Processed 2650 images out of 16971.\n",
      "Processed 2700 images out of 16971.\n",
      "Processed 2750 images out of 16971.\n",
      "Processed 2800 images out of 16971.\n",
      "Processed 2850 images out of 16971.\n",
      "Processed 2900 images out of 16971.\n",
      "Processed 2950 images out of 16971.\n",
      "Processed 3000 images out of 16971.\n",
      "Processed 3050 images out of 16971.\n",
      "Processed 3100 images out of 16971.\n",
      "Processed 3150 images out of 16971.\n",
      "Processed 3200 images out of 16971.\n",
      "Processed 3250 images out of 16971.\n",
      "Processed 3300 images out of 16971.\n",
      "Processed 3350 images out of 16971.\n",
      "Processed 3400 images out of 16971.\n",
      "Processed 3450 images out of 16971.\n",
      "Processed 3500 images out of 16971.\n",
      "Processed 3550 images out of 16971.\n",
      "Processed 3600 images out of 16971.\n",
      "Processed 3650 images out of 16971.\n",
      "Processed 3700 images out of 16971.\n",
      "Processed 3750 images out of 16971.\n",
      "Processed 3800 images out of 16971.\n",
      "Processed 3850 images out of 16971.\n",
      "Processed 3900 images out of 16971.\n",
      "Processed 3950 images out of 16971.\n",
      "Processed 4000 images out of 16971.\n",
      "Processed 4050 images out of 16971.\n",
      "Processed 4100 images out of 16971.\n",
      "Processed 4150 images out of 16971.\n",
      "Processed 4200 images out of 16971.\n",
      "Processed 4250 images out of 16971.\n",
      "Processed 4300 images out of 16971.\n",
      "Processed 4350 images out of 16971.\n",
      "Processed 4400 images out of 16971.\n",
      "Processed 4450 images out of 16971.\n",
      "Processed 4500 images out of 16971.\n",
      "Processed 4550 images out of 16971.\n",
      "Processed 4600 images out of 16971.\n",
      "Processed 4650 images out of 16971.\n",
      "Processed 4700 images out of 16971.\n",
      "Processed 4750 images out of 16971.\n",
      "Processed 4800 images out of 16971.\n",
      "Processed 4850 images out of 16971.\n",
      "Processed 4900 images out of 16971.\n",
      "Processed 4950 images out of 16971.\n",
      "Processed 5000 images out of 16971.\n",
      "Processed 5050 images out of 16971.\n",
      "Processed 5100 images out of 16971.\n",
      "Processed 5150 images out of 16971.\n",
      "Processed 5200 images out of 16971.\n",
      "Processed 5250 images out of 16971.\n",
      "Processed 5300 images out of 16971.\n",
      "Processed 5350 images out of 16971.\n",
      "Processed 5400 images out of 16971.\n",
      "Processed 5450 images out of 16971.\n",
      "Processed 5500 images out of 16971.\n",
      "Processed 5550 images out of 16971.\n",
      "Processed 5600 images out of 16971.\n",
      "Processed 5650 images out of 16971.\n",
      "Processed 5700 images out of 16971.\n",
      "Processed 5750 images out of 16971.\n",
      "Processed 5800 images out of 16971.\n",
      "Processed 5850 images out of 16971.\n",
      "Processed 5900 images out of 16971.\n",
      "Processed 5950 images out of 16971.\n",
      "Processed 6000 images out of 16971.\n",
      "Processed 6050 images out of 16971.\n",
      "Processed 6100 images out of 16971.\n",
      "Processed 6150 images out of 16971.\n",
      "Processed 6200 images out of 16971.\n",
      "Processed 6250 images out of 16971.\n",
      "Processed 6300 images out of 16971.\n",
      "Processed 6350 images out of 16971.\n",
      "Processed 6400 images out of 16971.\n",
      "Processed 6450 images out of 16971.\n",
      "Processed 6500 images out of 16971.\n",
      "Processed 6550 images out of 16971.\n",
      "Processed 6600 images out of 16971.\n",
      "Processed 6650 images out of 16971.\n",
      "Processed 6700 images out of 16971.\n",
      "Processed 6750 images out of 16971.\n",
      "Processed 6800 images out of 16971.\n",
      "Processed 6850 images out of 16971.\n",
      "Processed 6900 images out of 16971.\n",
      "Processed 6950 images out of 16971.\n",
      "Processed 7000 images out of 16971.\n",
      "Processed 7050 images out of 16971.\n",
      "Processed 7100 images out of 16971.\n",
      "Processed 7150 images out of 16971.\n",
      "Processed 7200 images out of 16971.\n",
      "Processed 7250 images out of 16971.\n",
      "Processed 7300 images out of 16971.\n",
      "Processed 7350 images out of 16971.\n",
      "Processed 7400 images out of 16971.\n",
      "Processed 7450 images out of 16971.\n",
      "Processed 7500 images out of 16971.\n",
      "Processed 7550 images out of 16971.\n",
      "Processed 7600 images out of 16971.\n",
      "Processed 7650 images out of 16971.\n",
      "Processed 7700 images out of 16971.\n",
      "Processed 7750 images out of 16971.\n",
      "Processed 7800 images out of 16971.\n",
      "Processed 7850 images out of 16971.\n",
      "Processed 7900 images out of 16971.\n",
      "Processed 7950 images out of 16971.\n",
      "Processed 8000 images out of 16971.\n",
      "Processed 8050 images out of 16971.\n",
      "Processed 8100 images out of 16971.\n",
      "Processed 8150 images out of 16971.\n",
      "Processed 8200 images out of 16971.\n",
      "Processed 8250 images out of 16971.\n",
      "Processed 8300 images out of 16971.\n",
      "Processed 8350 images out of 16971.\n",
      "Processed 8400 images out of 16971.\n",
      "Processed 8450 images out of 16971.\n",
      "Processed 8500 images out of 16971.\n",
      "Processed 8550 images out of 16971.\n",
      "Processed 8600 images out of 16971.\n",
      "Processed 8650 images out of 16971.\n",
      "Processed 8700 images out of 16971.\n",
      "Processed 8750 images out of 16971.\n",
      "Processed 8800 images out of 16971.\n",
      "Processed 8850 images out of 16971.\n",
      "Processed 8900 images out of 16971.\n",
      "Processed 8950 images out of 16971.\n",
      "Processed 9000 images out of 16971.\n",
      "Processed 9050 images out of 16971.\n",
      "Processed 9100 images out of 16971.\n",
      "Processed 9150 images out of 16971.\n",
      "Processed 9200 images out of 16971.\n",
      "Processed 9250 images out of 16971.\n",
      "Processed 9300 images out of 16971.\n",
      "Processed 9350 images out of 16971.\n",
      "Processed 9400 images out of 16971.\n",
      "Processed 9450 images out of 16971.\n",
      "Processed 9500 images out of 16971.\n",
      "Processed 9550 images out of 16971.\n",
      "Processed 9600 images out of 16971.\n",
      "Processed 9650 images out of 16971.\n",
      "Processed 9700 images out of 16971.\n",
      "Processed 9750 images out of 16971.\n",
      "Processed 9800 images out of 16971.\n",
      "Processed 9850 images out of 16971.\n",
      "Processed 9900 images out of 16971.\n",
      "Processed 9950 images out of 16971.\n",
      "Processed 10000 images out of 16971.\n",
      "Processed 10050 images out of 16971.\n",
      "Processed 10100 images out of 16971.\n",
      "Processed 10150 images out of 16971.\n",
      "Processed 10200 images out of 16971.\n",
      "Processed 10250 images out of 16971.\n",
      "Processed 10300 images out of 16971.\n",
      "Processed 10350 images out of 16971.\n",
      "Processed 10400 images out of 16971.\n",
      "Processed 10450 images out of 16971.\n",
      "Processed 10500 images out of 16971.\n",
      "Processed 10550 images out of 16971.\n",
      "Processed 10600 images out of 16971.\n",
      "Processed 10650 images out of 16971.\n",
      "Processed 10700 images out of 16971.\n",
      "Processed 10750 images out of 16971.\n",
      "Processed 10800 images out of 16971.\n",
      "Processed 10850 images out of 16971.\n",
      "Processed 10900 images out of 16971.\n",
      "Processed 10950 images out of 16971.\n",
      "Processed 11000 images out of 16971.\n",
      "Processed 11050 images out of 16971.\n",
      "Processed 11100 images out of 16971.\n",
      "Processed 11150 images out of 16971.\n",
      "Processed 11200 images out of 16971.\n",
      "Processed 11250 images out of 16971.\n",
      "Processed 11300 images out of 16971.\n",
      "Processed 11350 images out of 16971.\n",
      "Processed 11400 images out of 16971.\n",
      "Processed 11450 images out of 16971.\n",
      "Processed 11500 images out of 16971.\n",
      "Processed 11550 images out of 16971.\n",
      "Processed 11600 images out of 16971.\n",
      "Processed 11650 images out of 16971.\n",
      "Processed 11700 images out of 16971.\n",
      "Processed 11750 images out of 16971.\n",
      "Processed 11800 images out of 16971.\n",
      "Processed 11850 images out of 16971.\n",
      "Processed 11900 images out of 16971.\n",
      "Processed 11950 images out of 16971.\n",
      "Processed 12000 images out of 16971.\n",
      "Processed 12050 images out of 16971.\n",
      "Processed 12100 images out of 16971.\n",
      "Processed 12150 images out of 16971.\n",
      "Processed 12200 images out of 16971.\n",
      "Processed 12250 images out of 16971.\n",
      "Processed 12300 images out of 16971.\n",
      "Processed 12350 images out of 16971.\n",
      "Processed 12400 images out of 16971.\n",
      "Processed 12450 images out of 16971.\n",
      "Processed 12500 images out of 16971.\n",
      "Processed 12550 images out of 16971.\n",
      "Processed 12600 images out of 16971.\n",
      "Processed 12650 images out of 16971.\n",
      "Processed 12700 images out of 16971.\n",
      "Processed 12750 images out of 16971.\n",
      "Processed 12800 images out of 16971.\n",
      "Processed 12850 images out of 16971.\n",
      "Processed 12900 images out of 16971.\n",
      "Processed 12950 images out of 16971.\n",
      "Processed 13000 images out of 16971.\n",
      "Processed 13050 images out of 16971.\n",
      "Processed 13100 images out of 16971.\n",
      "Processed 13150 images out of 16971.\n",
      "Processed 13200 images out of 16971.\n",
      "Processed 13250 images out of 16971.\n",
      "Processed 13300 images out of 16971.\n",
      "Processed 13350 images out of 16971.\n",
      "Processed 13400 images out of 16971.\n",
      "Processed 13450 images out of 16971.\n",
      "Processed 13500 images out of 16971.\n",
      "Processed 13550 images out of 16971.\n",
      "Processed 13600 images out of 16971.\n",
      "Processed 13650 images out of 16971.\n",
      "Processed 13700 images out of 16971.\n",
      "Processed 13750 images out of 16971.\n",
      "Processed 13800 images out of 16971.\n",
      "Processed 13850 images out of 16971.\n",
      "Processed 13900 images out of 16971.\n",
      "Processed 13950 images out of 16971.\n",
      "Processed 14000 images out of 16971.\n",
      "Processed 14050 images out of 16971.\n",
      "Processed 14100 images out of 16971.\n",
      "Processed 14150 images out of 16971.\n",
      "Processed 14200 images out of 16971.\n",
      "Processed 14250 images out of 16971.\n",
      "Processed 14300 images out of 16971.\n",
      "Processed 14350 images out of 16971.\n",
      "Processed 14400 images out of 16971.\n",
      "Processed 14450 images out of 16971.\n",
      "Processed 14500 images out of 16971.\n",
      "Processed 14550 images out of 16971.\n",
      "Processed 14600 images out of 16971.\n",
      "Processed 14650 images out of 16971.\n",
      "Processed 14700 images out of 16971.\n",
      "Processed 14750 images out of 16971.\n",
      "Processed 14800 images out of 16971.\n",
      "Processed 14850 images out of 16971.\n",
      "Processed 14900 images out of 16971.\n",
      "Processed 14950 images out of 16971.\n",
      "Processed 15000 images out of 16971.\n",
      "Processed 15050 images out of 16971.\n",
      "Processed 15100 images out of 16971.\n",
      "Processed 15150 images out of 16971.\n",
      "Processed 15200 images out of 16971.\n",
      "Processed 15250 images out of 16971.\n",
      "Processed 15300 images out of 16971.\n",
      "Processed 15350 images out of 16971.\n",
      "Processed 15400 images out of 16971.\n",
      "Processed 15450 images out of 16971.\n",
      "Processed 15500 images out of 16971.\n",
      "Processed 15550 images out of 16971.\n",
      "Processed 15600 images out of 16971.\n",
      "Processed 15650 images out of 16971.\n",
      "Processed 15700 images out of 16971.\n",
      "Processed 15750 images out of 16971.\n",
      "Processed 15800 images out of 16971.\n",
      "Processed 15850 images out of 16971.\n",
      "Processed 15900 images out of 16971.\n",
      "Processed 15950 images out of 16971.\n",
      "Processed 16000 images out of 16971.\n",
      "Processed 16050 images out of 16971.\n",
      "Processed 16100 images out of 16971.\n",
      "Processed 16150 images out of 16971.\n",
      "Processed 16200 images out of 16971.\n",
      "Processed 16250 images out of 16971.\n",
      "Processed 16300 images out of 16971.\n",
      "Processed 16350 images out of 16971.\n",
      "Processed 16400 images out of 16971.\n",
      "Processed 16450 images out of 16971.\n",
      "Processed 16500 images out of 16971.\n",
      "Processed 16550 images out of 16971.\n",
      "Processed 16600 images out of 16971.\n",
      "Processed 16650 images out of 16971.\n",
      "Processed 16700 images out of 16971.\n",
      "Processed 16750 images out of 16971.\n",
      "Processed 16800 images out of 16971.\n",
      "Processed 16850 images out of 16971.\n",
      "Processed 16900 images out of 16971.\n",
      "Processed 16950 images out of 16971.\n",
      "Dataset creation completed.\n"
     ]
    }
   ],
   "source": [
    "dataset_creation(traindf, destination_path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation Set"
   ],
   "metadata": {
    "id": "vHbj-hwVy7PN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_creation(valdf, destination_path_valid)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOUZXXqkXYyw",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700070090946,
     "user_tz": -60,
     "elapsed": 66681,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "bb5dbd93-04a5-4e44-cd49-a06dece1f6b9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 50 images out of 2125.\n",
      "Processed 100 images out of 2125.\n",
      "Processed 150 images out of 2125.\n",
      "Processed 200 images out of 2125.\n",
      "Processed 250 images out of 2125.\n",
      "Processed 300 images out of 2125.\n",
      "Processed 350 images out of 2125.\n",
      "Processed 400 images out of 2125.\n",
      "Processed 450 images out of 2125.\n",
      "Processed 500 images out of 2125.\n",
      "Processed 550 images out of 2125.\n",
      "Processed 600 images out of 2125.\n",
      "Processed 650 images out of 2125.\n",
      "Processed 700 images out of 2125.\n",
      "Processed 750 images out of 2125.\n",
      "Processed 800 images out of 2125.\n",
      "Processed 850 images out of 2125.\n",
      "Processed 900 images out of 2125.\n",
      "Processed 950 images out of 2125.\n",
      "Processed 1000 images out of 2125.\n",
      "Processed 1050 images out of 2125.\n",
      "Processed 1100 images out of 2125.\n",
      "Processed 1150 images out of 2125.\n",
      "Processed 1200 images out of 2125.\n",
      "Processed 1250 images out of 2125.\n",
      "Processed 1300 images out of 2125.\n",
      "Processed 1350 images out of 2125.\n",
      "Processed 1400 images out of 2125.\n",
      "Processed 1450 images out of 2125.\n",
      "Processed 1500 images out of 2125.\n",
      "Processed 1550 images out of 2125.\n",
      "Processed 1600 images out of 2125.\n",
      "Processed 1650 images out of 2125.\n",
      "Processed 1700 images out of 2125.\n",
      "Processed 1750 images out of 2125.\n",
      "Processed 1800 images out of 2125.\n",
      "Processed 1850 images out of 2125.\n",
      "Processed 1900 images out of 2125.\n",
      "Processed 1950 images out of 2125.\n",
      "Processed 2000 images out of 2125.\n",
      "Processed 2050 images out of 2125.\n",
      "Processed 2100 images out of 2125.\n",
      "Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heuENwg0QUSP"
   },
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOQbfFg8K635",
    "outputId": "50f11475-3f90-4ab0-ec9d-8c3bb97d9207",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700071899825,
     "user_tz": -60,
     "elapsed": 473612,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 50 images out of 2126.\n",
      "Processed 100 images out of 2126.\n",
      "Processed 150 images out of 2126.\n",
      "Processed 200 images out of 2126.\n",
      "Processed 250 images out of 2126.\n",
      "Processed 300 images out of 2126.\n",
      "Processed 350 images out of 2126.\n",
      "Processed 400 images out of 2126.\n",
      "Processed 450 images out of 2126.\n",
      "Processed 500 images out of 2126.\n",
      "Processed 550 images out of 2126.\n",
      "Processed 600 images out of 2126.\n",
      "Processed 650 images out of 2126.\n",
      "Processed 700 images out of 2126.\n",
      "Processed 750 images out of 2126.\n",
      "Processed 800 images out of 2126.\n",
      "Processed 850 images out of 2126.\n",
      "Processed 900 images out of 2126.\n",
      "Processed 950 images out of 2126.\n",
      "Processed 1000 images out of 2126.\n",
      "Processed 1050 images out of 2126.\n",
      "Processed 1100 images out of 2126.\n",
      "Processed 1150 images out of 2126.\n",
      "Processed 1200 images out of 2126.\n",
      "Processed 1250 images out of 2126.\n",
      "Processed 1300 images out of 2126.\n",
      "Processed 1350 images out of 2126.\n",
      "Processed 1400 images out of 2126.\n",
      "Processed 1450 images out of 2126.\n",
      "Processed 1500 images out of 2126.\n",
      "Processed 1550 images out of 2126.\n",
      "Processed 1600 images out of 2126.\n",
      "Processed 1650 images out of 2126.\n",
      "Processed 1700 images out of 2126.\n",
      "Processed 1750 images out of 2126.\n",
      "Processed 1800 images out of 2126.\n",
      "Processed 1850 images out of 2126.\n",
      "Processed 1900 images out of 2126.\n",
      "Processed 1950 images out of 2126.\n",
      "Processed 2000 images out of 2126.\n",
      "Processed 2050 images out of 2126.\n",
      "Processed 2100 images out of 2126.\n",
      "Dataset creation completed.\n"
     ]
    }
   ],
   "source": [
    "dataset_creation(testdf, destination_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1700068988756,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     },
     "user_tz": -60
    },
    "id": "ZmbeCDtmCbs9",
    "outputId": "c677efee-2b37-470d-fd59-65ab37cfa5bd"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of parent folders: 0\n",
      "Total number of files in all folders: 0\n",
      "Average number of files in a folder: 0.00\n",
      "Total size of /content/drive/MyDrive/ABELE_prostate/claudio/black_box/data/dataset/test/: 0.00 Gigabytes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(output_dir, 'val', 'test')\n",
    "\n",
    "total_size = 0\n",
    "num_patient_folders = 0\n",
    "total_files = 0\n",
    "\n",
    "for dirpath, dirnames, filenames in tqdm(os.walk(output_path)):\n",
    "    for dirname in dirnames:\n",
    "        if dirname.isdigit():\n",
    "            num_patient_folders += 1\n",
    "            folder_path = os.path.join(dirpath, dirname)\n",
    "            num_files_in_folder = len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
    "            total_files += num_files_in_folder\n",
    "\n",
    "    for filename in filenames:\n",
    "        filepath = os.path.join(dirpath, filename)\n",
    "        total_size += os.path.getsize(filepath)\n",
    "\n",
    "average_files_per_folder = total_files / num_patient_folders if num_patient_folders > 0 else 0\n",
    "\n",
    "print(f'Total number of parent folders: {num_patient_folders}')\n",
    "print(f'Total number of files in all folders: {total_files}')\n",
    "print(f'Average number of files in a folder: {average_files_per_folder:.2f}')\n",
    "print(f'Total size of {output_path}: {total_size / (1024 ** 3):.2f} Gigabytes')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "file_checker(destination_path_train)"
   ],
   "metadata": {
    "id": "DflwD5rbwEIH",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1700132690767,
     "user_tz": -60,
     "elapsed": 19523,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "98a3f398-04ff-4494-a407-15c0afea0020"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "3it [00:19,  6.36s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Total number of patient folders: 2\n",
      "Total number of patient files: 16971\n",
      "Total size of n: 0.08 Gigabytes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Dataset Creation (Separated)\n"
   ],
   "metadata": {
    "id": "5zkDRkn7TjR-"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training set (adc)"
   ],
   "metadata": {
    "id": "3RvMuFnvT2de"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(traindf_adc)\n",
    "step_size = 500\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_train_adc, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_train_adc, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in traindf_adc.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('train ADC Dataset creation completed.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HBxYpBzcTojV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694598309977,
     "user_tz": -120,
     "elapsed": 3940316,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "89a7c105-cfbe-45ba-b496-ea3f2cc66327"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 5201.\n",
      "Processed 500 images out of 5201.\n",
      "Processed 1000 images out of 5201.\n",
      "Processed 1500 images out of 5201.\n",
      "Processed 2000 images out of 5201.\n",
      "Processed 2500 images out of 5201.\n",
      "Processed 3000 images out of 5201.\n",
      "Processed 3500 images out of 5201.\n",
      "Processed 4000 images out of 5201.\n",
      "Processed 4500 images out of 5201.\n",
      "Processed 5000 images out of 5201.\n",
      "train ADC Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## validation set (adc)"
   ],
   "metadata": {
    "id": "iVUxRsWTUnIs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(valdf_adc)\n",
    "step_size = 250\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_valid_adc, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_valid_adc, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in valdf_adc.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('validation ADC Dataset creation completed.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttn7uw8VUfOq",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694590430670,
     "user_tz": -120,
     "elapsed": 823794,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "2d301a90-cef8-4bce-bce6-72fd6fcc232b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 1121.\n",
      "Processed 250 images out of 1121.\n",
      "Processed 500 images out of 1121.\n",
      "Processed 750 images out of 1121.\n",
      "Processed 1000 images out of 1121.\n",
      "validation ADC Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test set (adc)"
   ],
   "metadata": {
    "id": "Uiy0r5x1T8SX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(testdf_adc)\n",
    "step_size = 250\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_test_adc, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_test_adc, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in testdf_adc.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('test ADC Dataset creation completed.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-qRENM3rTocG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694594222007,
     "user_tz": -120,
     "elapsed": 882421,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "052a4e37-4af0-46a4-ece3-15b8830b6709"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 1109.\n",
      "Processed 250 images out of 1109.\n",
      "Processed 500 images out of 1109.\n",
      "Processed 750 images out of 1109.\n",
      "Processed 1000 images out of 1109.\n",
      "validation ADC Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output_csv_path = os.path.join(BASE_DIR, 'black_box', 'data ', 'CSV', 'prostate_centered' ,'80x80')\n",
    "output_csv_path_adc = os.path.join(output_csv_path, 'adc')\n",
    "total_size = 0\n",
    "num_patient_folders = 0\n",
    "total_files = 0\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(output_csv_path_adc)):\n",
    "    for dir_ in dirs:\n",
    "        patient_folder = os.path.join(root, dir_)\n",
    "        for class_folder in os.listdir(patient_folder):\n",
    "            class_folder_path = os.path.join(patient_folder, class_folder)\n",
    "            if os.path.isdir(class_folder_path):\n",
    "                num_files_in_folder = len([f for f in os.listdir(class_folder_path) if os.path.isfile(os.path.join(class_folder_path, f))])\n",
    "                total_files += num_files_in_folder\n",
    "                num_patient_folders += 1\n",
    "\n",
    "    for file_ in files:\n",
    "        file_path = os.path.join(root, file_)\n",
    "        total_size += os.path.getsize(file_path)\n",
    "\n",
    "average_files_per_folder = total_files / num_patient_folders if num_patient_folders > 0 else 0\n",
    "\n",
    "print(f'Total number of patient folders: {num_patient_folders}')\n",
    "print(f'Total number of files in all folders: {total_files}')\n",
    "print(f'Average number of files per patient folder: {average_files_per_folder:.2f}')\n",
    "print(f'Total size of {output_csv_path_adc}: {total_size / (1024 ** 3):.2f} Gigabytes')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbJxxkLypxeg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694600442569,
     "user_tz": -120,
     "elapsed": 13466,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "b82a1bf2-5f8d-4c41-a9c0-6739e7f39549"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:12,  1.28s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of patient folders: 6\n",
      "Total number of files in all folders: 7249\n",
      "Average number of files per patient folder: 1208.17\n",
      "Total size of /content/drive/MyDrive/ABELE_prostate/claudio/black_box/data/CSV/prostate_centered/80x80/adc/: 0.03 Gigabytes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## training set (t2w)"
   ],
   "metadata": {
    "id": "fYzdZb6Ro2Sc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(traindf_t2w)\n",
    "step_size = 500\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_train_t2w, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_train_t2w, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in traindf_t2w.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('train T2W Dataset creation completed.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlvNmdczToTW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694603984914,
     "user_tz": -120,
     "elapsed": 3471667,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "3c321c09-ccd1-456d-fdef-b74b5dec8708"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 5201.\n",
      "Processed 500 images out of 5201.\n",
      "Processed 1000 images out of 5201.\n",
      "Processed 1500 images out of 5201.\n",
      "Processed 2000 images out of 5201.\n",
      "Processed 2500 images out of 5201.\n",
      "Processed 3000 images out of 5201.\n",
      "Processed 3500 images out of 5201.\n",
      "Processed 4000 images out of 5201.\n",
      "Processed 4500 images out of 5201.\n",
      "Processed 5000 images out of 5201.\n",
      "train T2W Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## validation set (t2w)"
   ],
   "metadata": {
    "id": "0PfFjDClo6Ru"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(valdf_t2w)\n",
    "step_size = 250\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_valid_t2w, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_valid_t2w, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in valdf_t2w.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('validation T2W Dataset creation completed.')"
   ],
   "metadata": {
    "id": "xNUbG1B4JgBP",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694604818302,
     "user_tz": -120,
     "elapsed": 833394,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "18007620-9bba-463a-8faa-5c66c7e625c7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 1121.\n",
      "Processed 250 images out of 1121.\n",
      "Processed 500 images out of 1121.\n",
      "Processed 750 images out of 1121.\n",
      "Processed 1000 images out of 1121.\n",
      "validation T2W Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test set (t2w)"
   ],
   "metadata": {
    "id": "5N8Ahp5Bo9bI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "total_images = len(testdf_t2w)\n",
    "step_size = 250\n",
    "processed_images = 0\n",
    "progress_updates = 0\n",
    "\n",
    "# Create the class folders if they don't exist\n",
    "not_clinically_relevant_folder = os.path.join(destination_path_test_t2w, '0')\n",
    "clinically_relevant_folder = os.path.join(destination_path_test_t2w, '1')\n",
    "\n",
    "if not os.path.exists(not_clinically_relevant_folder):\n",
    "    os.makedirs(not_clinically_relevant_folder)\n",
    "\n",
    "if not os.path.exists(clinically_relevant_folder):\n",
    "    os.makedirs(clinically_relevant_folder)\n",
    "\n",
    "# Iterate over each row in the CSV file\n",
    "for _, row in testdf_t2w.iterrows():\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    # Get the image filename\n",
    "    image_filename = os.path.basename(image_path)\n",
    "\n",
    "    # Append the class label to the image filename before the file extension\n",
    "    filename_parts = os.path.splitext(image_filename)\n",
    "    image_filename_with_class = f'{filename_parts[0]}_class{label}{filename_parts[1]}'\n",
    "\n",
    "    # Construct the new image path in the destination folder\n",
    "    destination_path = os.path.join(clinically_relevant_folder if label == 1 else not_clinically_relevant_folder, image_filename_with_class)\n",
    "    image = Image.open(image_path).convert('L')\n",
    "    # Save the converted image to the destination folder\n",
    "    image.save(destination_path)\n",
    "    processed_images += 1\n",
    "\n",
    "    if processed_images >= progress_updates * step_size:\n",
    "        print(f'Processed {processed_images} images out of {total_images}.')\n",
    "        progress_updates += 1\n",
    "\n",
    "print('test T2W Dataset creation completed.')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OmGeulvro82Y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694605554250,
     "user_tz": -120,
     "elapsed": 735955,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "cb41a0d2-3a22-4345-9d22-e778170e9578"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processed 1 images out of 1109.\n",
      "Processed 250 images out of 1109.\n",
      "Processed 500 images out of 1109.\n",
      "Processed 750 images out of 1109.\n",
      "Processed 1000 images out of 1109.\n",
      "test T2W Dataset creation completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "output_csv_path = os.path.join(BASE_DIR, 'black_box', 'data ', 'CSV', 'prostate_centered' ,'80x80')\n",
    "output_csv_path_t2w = os.path.join(output_csv_path, 't2w')\n",
    "\n",
    "total_size = 0\n",
    "num_patient_folders = 0\n",
    "total_files = 0\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(output_csv_path_t2w)):\n",
    "    for dir_ in dirs:\n",
    "        patient_folder = os.path.join(root, dir_)\n",
    "        for class_folder in os.listdir(patient_folder):\n",
    "            class_folder_path = os.path.join(patient_folder, class_folder)\n",
    "            if os.path.isdir(class_folder_path):\n",
    "                num_files_in_folder = len([f for f in os.listdir(class_folder_path) if os.path.isfile(os.path.join(class_folder_path, f))])\n",
    "                total_files += num_files_in_folder\n",
    "                num_patient_folders += 1\n",
    "\n",
    "    for file_ in files:\n",
    "        file_path = os.path.join(root, file_)\n",
    "        total_size += os.path.getsize(file_path)\n",
    "\n",
    "average_files_per_folder = total_files / num_patient_folders if num_patient_folders > 0 else 0\n",
    "\n",
    "print(f'Total number of patient folders: {num_patient_folders}')\n",
    "print(f'Total number of files in all folders: {total_files}')\n",
    "print(f'Average number of files per patient folder: {average_files_per_folder:.2f}')\n",
    "print(f'Total size of {output_csv_path_t2w}: {total_size / (1024 ** 3):.2f} Gigabytes')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7otDqwjopncX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1694605567226,
     "user_tz": -120,
     "elapsed": 12564,
     "user": {
      "displayName": "claudio giovannoni",
      "userId": "16814477495340547867"
     }
    },
    "outputId": "865e82f2-b65b-4d23-bb1b-b37e22d22e76"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "10it [00:12,  1.29s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of patient folders: 6\n",
      "Total number of files in all folders: 7249\n",
      "Average number of files per patient folder: 1208.17\n",
      "Total size of /content/drive/MyDrive/ABELE_prostate/claudio/black_box/data/CSV/prostate_centered/80x80/t2w/: 0.03 Gigabytes\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9zPcxpFuTQCA",
    "5zkDRkn7TjR-"
   ],
   "provenance": [],
   "authorship_tag": "ABX9TyMNEa1nEoc2AimbtpLKhL+p"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
